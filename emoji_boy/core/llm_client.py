"""
å¤§æ¨¡å‹æ¥å£æ¨¡å—
"""

import os
import json
import time
import requests
from typing import Optional, Dict, Any, List
import config
from .config_manager import config_manager


class LLMClient:
    """å¤§æ¨¡å‹å®¢æˆ·ç«¯"""
    
    def __init__(self, api_type="openai", model_name=None):
        """
        åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
        
        Args:
            api_type: APIç±»å‹ ("openai", "huggingface", "mock")
            model_name: æ¨¡å‹åç§°
        """
        self.api_type = api_type
        
        # é…ç½®ç¼“å­˜ - å¿…é¡»åœ¨å…¶ä»–æ–¹æ³•è°ƒç”¨ä¹‹å‰åˆå§‹åŒ–
        self._config_cache = None
        self._config_loaded = False
        
        # ç°åœ¨å¯ä»¥å®‰å…¨è°ƒç”¨ä¾èµ–é…ç½®çš„æ–¹æ³•
        self.model_name = model_name or self._get_default_model()
        
        # APIé…ç½®
        self.api_key = self._get_api_key()
        self.api_base = self._get_api_base()
        
        # è¯·æ±‚é…ç½®
        self.timeout = 30
        self.max_retries = 3
        self.retry_delay = 1
        
        # ä¼šè¯å†å²
        self.conversation_history = []
        self.max_history = 10
        
        # system_prompt ä¸å†åœ¨initæ—¶é™æ€èµ‹å€¼
        # self.system_prompt = self._get_system_prompt()
    
    def _get_default_model(self) -> str:
        """è·å–é»˜è®¤æ¨¡å‹åç§°"""
        # ä¼˜å…ˆä»é…ç½®ç®¡ç†å™¨è·å–
        saved_config = self._get_cached_config()
        if saved_config and saved_config.get('model_name'):
            return saved_config['model_name']
        
        # ä»é»˜è®¤é…ç½®è·å–
        model_map = {
            "openai": "gpt-3.5-turbo",
            "huggingface": "gpt2",
            "mock": "mock-model"
        }
        return model_map.get(self.api_type, "gpt-3.5-turbo")
    
    def _get_api_key(self) -> Optional[str]:
        """è·å–APIå¯†é’¥"""
        # ä¼˜å…ˆä»é…ç½®ç®¡ç†å™¨è·å–
        saved_config = self._get_cached_config()
        if saved_config and saved_config.get('api_key'):
            return saved_config['api_key']
        
        # ä»ç¯å¢ƒå˜é‡è·å–
        if self.api_type == "openai":
            return os.getenv("OPENAI_API_KEY") or config.OPENAI_API_KEY
        elif self.api_type == "huggingface":
            return os.getenv("HUGGINGFACE_API_KEY") or config.HUGGINGFACE_API_KEY
        return None
    
    def _get_api_base(self) -> str:
        """è·å–APIåŸºç¡€URL"""
        # ä¼˜å…ˆä»é…ç½®ç®¡ç†å™¨è·å–
        saved_config = self._get_cached_config()
        if saved_config and saved_config.get('api_base'):
            return saved_config['api_base']
        
        # ä»é»˜è®¤é…ç½®è·å–
        if self.api_type == "openai":
            return "https://api.openai.com/v1"
        elif self.api_type == "huggingface":
            return "https://api-inference.huggingface.co"
        return ""
    
    def _get_cached_config(self) -> Optional[Dict[str, str]]:
        """è·å–ç¼“å­˜çš„é…ç½®"""
        if not self._config_loaded:
            self._config_cache = config_manager.load_config()
            self._config_loaded = True
        return self._config_cache
    
    def _get_system_prompt(self) -> str:
        """è·å–å®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯ï¼ŒåŒ…å«AIçµé­‚ï¼ˆsystemprompt.txtï¼‰å’Œæ½œæ„è¯†ï¼ˆmemC.txtï¼‰"""
        import os
        import sys
        
        # 1. åŠ è½½AIçµé­‚ï¼ˆç³»ç»Ÿæç¤ºè¯ï¼‰
        system_prompt = self._load_ai_soul()
        
        # 2. åŠ è½½AIæ½œæ„è¯†ï¼ˆmemCè®°å¿†ï¼‰
        memc_content = self._load_ai_subconscious()
        
        # 3. ç»„åˆå®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯
        if memc_content:
            complete_prompt = f"{system_prompt}\n\n# æ½œæ„è¯†è®°å¿†\n{memc_content}"
            print(f"âœ… å®Œæ•´ç³»ç»Ÿæç¤ºè¯: AIçµé­‚({len(system_prompt)}å­—ç¬¦) + æ½œæ„è¯†({len(memc_content)}å­—ç¬¦)")
        else:
            complete_prompt = system_prompt
            print(f"âœ… ç³»ç»Ÿæç¤ºè¯: AIçµé­‚({len(system_prompt)}å­—ç¬¦) + æ— æ½œæ„è¯†è®°å¿†")
        
        return complete_prompt
    
    def _load_ai_soul(self) -> str:
        """åŠ è½½AIçµé­‚ï¼ˆç³»ç»Ÿæç¤ºè¯ï¼‰"""
        import os
        import sys
        
        system_prompt_path = os.path.join(os.path.dirname(__file__), '../MemABC/systemprompt.txt')
        
        try:
            with open(system_prompt_path, 'r', encoding='utf-8') as f:
                system_prompt = f.read().strip()
            
            if system_prompt:
                return system_prompt
            else:
                print("âŒ ç³»ç»Ÿæç¤ºè¯æ–‡ä»¶ä¸ºç©º")
                sys.exit(1)
                
        except FileNotFoundError:
            print("âŒ ç³»ç»Ÿæç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: systemprompt.txt")
            print("ğŸ’¡ è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ï¼š")
            print("   cd emoji_boy/MemABC && ./memC_to_system_prompt.sh --init")
            print("   æˆ–è€…ä»memCç”Ÿæˆä¸ªæ€§åŒ–ç³»ç»Ÿæç¤ºè¯ï¼š")
            print("   cd emoji_boy/MemABC && ./memC_to_system_prompt.sh")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ è¯»å–ç³»ç»Ÿæç¤ºè¯å¤±è´¥: {e}")
            sys.exit(1)
    
    def _load_ai_subconscious(self) -> str:
        """åŠ è½½AIæ½œæ„è¯†ï¼ˆmemCè®°å¿†ï¼‰"""
        import os
        
        memc_path = os.path.join(os.path.dirname(__file__), '../MemABC/memC/memC.txt')
        
        try:
            with open(memc_path, 'r', encoding='utf-8') as f:
                memc_content = f.read().strip()
            
            if memc_content:
                # å»æ‰å¤´éƒ¨æ ‡å¿—
                if memc_content.startswith('# memCè®°å¿†'):
                    memc_content = memc_content.split('\n', 1)[-1].strip()
                return memc_content
            else:
                print("âš ï¸ memCè®°å¿†æ–‡ä»¶ä¸ºç©ºï¼Œå°†åªä½¿ç”¨AIçµé­‚")
                return ""
                
        except FileNotFoundError:
            print("âš ï¸ memCè®°å¿†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åªä½¿ç”¨AIçµé­‚")
            return ""
        except Exception as e:
            print(f"âš ï¸ è¯»å–memCè®°å¿†å¤±è´¥: {e}ï¼Œå°†åªä½¿ç”¨AIçµé­‚")
            return ""
    
    @property
    def system_prompt(self):
        """
        æ¯æ¬¡è®¿é—®éƒ½åŠ¨æ€è¯»å–memCå†…å®¹ï¼Œä¿è¯æ½œæ„è¯†æœ€æ–°
        """
        return self._get_system_prompt()
    
    def get_response(self, message: str) -> str:
        """
        è·å–æ¨¡å‹å“åº”
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            æ¨¡å‹å“åº”æ–‡æœ¬
        """
        try:
            if self.api_type == "openai":
                return self._call_openai_api(message)
            elif self.api_type == "huggingface":
                return self._call_huggingface_api(message)
            elif self.api_type == "mock":
                return self._get_mock_response(message)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„APIç±»å‹: {self.api_type}")
                
        except Exception as e:
            print(f"âŒ è·å–æ¨¡å‹å“åº”å¤±è´¥: {e}")
            return self._get_fallback_response(message)
    
    def _call_openai_api(self, message: str) -> str:
        """è°ƒç”¨OpenAI API"""
        if not self.api_key:
            raise ValueError("OpenAI APIå¯†é’¥æœªè®¾ç½®")
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [{"role": "system", "content": self.system_prompt}]
        
        # æ·»åŠ å†å²å¯¹è¯
        for hist in self.conversation_history[-self.max_history:]:
            messages.append(hist)
        
        # æ·»åŠ å½“å‰æ¶ˆæ¯
        messages.append({"role": "user", "content": message})
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        data = {
            "model": self.model_name,
            "messages": messages,
            "max_tokens": 500,
            "temperature": 0.7,
            "top_p": 0.9
        }
        
        # å‘é€è¯·æ±‚
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        for attempt in range(self.max_retries):
            try:
                response = requests.post(
                    f"{self.api_base}/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=self.timeout
                )
                response.raise_for_status()
                
                result = response.json()
                assistant_message = result["choices"][0]["message"]["content"]
                
                # æ›´æ–°å¯¹è¯å†å²
                self._update_conversation_history(message, assistant_message)
                
                return assistant_message
                
            except requests.exceptions.RequestException as e:
                if attempt == self.max_retries - 1:
                    raise e
                time.sleep(self.retry_delay * (attempt + 1))
    
    def _call_huggingface_api(self, message: str) -> str:
        """è°ƒç”¨HuggingFace API"""
        if not self.api_key:
            raise ValueError("HuggingFace APIå¯†é’¥æœªè®¾ç½®")
        
        # æ„å»ºæç¤ºè¯
        prompt = f"{self.system_prompt}\n\nç”¨æˆ·: {message}\nå°å–µ:"
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        data = {
            "inputs": prompt,
            "parameters": {
                "max_new_tokens": 200,
                "temperature": 0.7,
                "top_p": 0.9,
                "do_sample": True
            }
        }
        
        # å‘é€è¯·æ±‚
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        for attempt in range(self.max_retries):
            try:
                response = requests.post(
                    f"{self.api_base}/models/{self.model_name}",
                    headers=headers,
                    json=data,
                    timeout=self.timeout
                )
                response.raise_for_status()
                
                result = response.json()
                assistant_message = result[0]["generated_text"]
                
                # æå–å›å¤éƒ¨åˆ†
                if "å°å–µ:" in assistant_message:
                    assistant_message = assistant_message.split("å°å–µ:")[-1].strip()
                
                # æ›´æ–°å¯¹è¯å†å²
                self._update_conversation_history(message, assistant_message)
                
                return assistant_message
                
            except requests.exceptions.RequestException as e:
                if attempt == self.max_retries - 1:
                    raise e
                time.sleep(self.retry_delay * (attempt + 1))
    
    def _get_mock_response(self, message: str) -> str:
        """è·å–æ¨¡æ‹Ÿå“åº”"""
        import random
        
        # æ¨¡æ‹Ÿå“åº”æ¨¡æ¿
        responses = [
            "å–µ~ æˆ‘ç†è§£ä½ çš„æƒ³æ³•å‘¢ ğŸ˜Š",
            "è¿™ä¸ªé—®é¢˜å¾ˆæœ‰è¶£ï¼Œè®©æˆ‘æƒ³æƒ³... ğŸ¤”",
            "ä½ è¯´å¾—å¯¹ï¼Œæˆ‘ä¹Ÿè¿™ä¹ˆè§‰å¾—ï¼ ğŸ‘",
            "å“ˆå“ˆï¼Œä½ çœŸæ˜¯å¤ªå¯çˆ±äº† ğŸ˜„",
            "æˆ‘åœ¨è¿™é‡Œé™ªç€ä½ å“¦ ğŸ’•",
            "è®©æˆ‘ä»¬ä¸€èµ·æƒ³æƒ³åŠæ³•å§ ğŸ’¡",
            "ä½ è¯´å¾—å¾ˆæ£’å‘¢ï¼ ğŸŒŸ",
            "æˆ‘å®Œå…¨ç†è§£ä½ çš„æ„Ÿå— ğŸ¤—",
            "è¿™ç¡®å®æ˜¯ä¸ªå¥½é—®é¢˜ âœ¨",
            "ä½ çš„æƒ³æ³•å¾ˆæœ‰åˆ›æ„å‘¢ ğŸ¨"
        ]
        
        # æ ¹æ®æ¶ˆæ¯å†…å®¹é€‰æ‹©å“åº”
        if any(word in message.lower() for word in ['ä½ å¥½', 'hello', 'hi']):
            return "ä½ å¥½å‘€ï¼æˆ‘æ˜¯å°å–µï¼Œå¾ˆé«˜å…´è§åˆ°ä½  ğŸ˜º"
        elif any(word in message.lower() for word in ['è°¢è°¢', 'æ„Ÿè°¢', 'thank']):
            return "ä¸å®¢æ°”ï¼èƒ½å¸®åˆ°ä½ æ˜¯æˆ‘çš„è£å¹¸ ğŸ’–"
        elif any(word in message.lower() for word in ['å†è§', 'æ‹œæ‹œ', 'bye']):
            return "å†è§å•¦ï¼è®°å¾—æƒ³æˆ‘å“¦ ğŸ‘‹"
        else:
            return random.choice(responses)
    
    def _get_fallback_response(self, message: str) -> str:
        """è·å–å¤‡ç”¨å“åº”"""
        return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æœ‰ç‚¹å°é—®é¢˜ï¼Œç¨åå†å’Œä½ èŠå¤©å§ ğŸ˜…"
    
    def _update_conversation_history(self, user_message: str, assistant_message: str):
        """æ›´æ–°å¯¹è¯å†å²"""
        self.conversation_history.extend([
            {"role": "user", "content": user_message},
            {"role": "assistant", "content": assistant_message}
        ])
        
        # ä¿æŒå†å²è®°å½•åœ¨é™åˆ¶èŒƒå›´å†…
        if len(self.conversation_history) > self.max_history * 2:
            self.conversation_history = self.conversation_history[-self.max_history * 2:]
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history.clear()
    
    def set_system_prompt(self, prompt: str):
        """è®¾ç½®ç³»ç»Ÿæç¤ºè¯"""
        self.system_prompt = prompt
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–å®¢æˆ·ç«¯çŠ¶æ€"""
        return {
            "api_type": self.api_type,
            "model_name": self.model_name,
            "has_api_key": bool(self.api_key),
            "history_length": len(self.conversation_history),
            "max_history": self.max_history
        }
    
    def test_connection(self) -> Dict[str, Any]:
        """
        æµ‹è¯•APIè¿æ¥
        
        Returns:
            åŒ…å«è¿æ¥çŠ¶æ€çš„å­—å…¸
        """
        result = {
            "success": False,
            "error": None,
            "details": {}
        }
        
        try:
            # æ£€æŸ¥åŸºæœ¬é…ç½®
            if not self.api_key:
                result["error"] = "APIå¯†é’¥æœªè®¾ç½®"
                return result
            
            if not self.api_base:
                result["error"] = "APIåŸºç¡€URLæœªè®¾ç½®"
                return result
            
            # æ ¹æ®APIç±»å‹è¿›è¡Œæµ‹è¯•
            if self.api_type == "openai":
                result = self._test_openai_connection()
            elif self.api_type == "huggingface":
                result = self._test_huggingface_connection()
            elif self.api_type == "mock":
                result = {
                    "success": True,
                    "error": None,
                    "details": {"message": "Mockæ¨¡å¼æ— éœ€è¿æ¥æµ‹è¯•"}
                }
            else:
                result["error"] = f"ä¸æ”¯æŒçš„APIç±»å‹: {self.api_type}"
                
        except Exception as e:
            result["error"] = str(e)
        
        return result
    
    def _test_openai_connection(self) -> Dict[str, Any]:
        """æµ‹è¯•OpenAI APIè¿æ¥"""
        result = {
            "success": False,
            "error": None,
            "details": {}
        }
        
        try:
            # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": self.model_name,
                "messages": [{"role": "user", "content": "Hello"}],
                "max_tokens": 10
            }
            
            response = requests.post(
                f"{self.api_base}/chat/completions",
                headers=headers,
                json=data,
                timeout=10
            )
            
            if response.status_code == 200:
                result["success"] = True
                result["details"] = {"status_code": response.status_code}
            else:
                result["error"] = f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                result["details"] = {"status_code": response.status_code, "response": response.text}
                
        except requests.exceptions.RequestException as e:
            result["error"] = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
        except Exception as e:
            result["error"] = f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
        
        return result
    
    def _test_huggingface_connection(self) -> Dict[str, Any]:
        """æµ‹è¯•HuggingFace APIè¿æ¥"""
        result = {
            "success": False,
            "error": None,
            "details": {}
        }
        
        try:
            # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "inputs": "Hello",
                "parameters": {
                    "max_new_tokens": 10,
                    "temperature": 0.7
                }
            }
            
            response = requests.post(
                f"{self.api_base}/models/{self.model_name}",
                headers=headers,
                json=data,
                timeout=10
            )
            
            if response.status_code == 200:
                result["success"] = True
                result["details"] = {"status_code": response.status_code}
            else:
                result["error"] = f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                result["details"] = {"status_code": response.status_code, "response": response.text}
                
        except requests.exceptions.RequestException as e:
            result["error"] = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
        except Exception as e:
            result["error"] = f"è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
        
        return result
    
    def update_config(self, api_type: str, api_key: str, api_base: str, model_name: str):
        """
        æ›´æ–°APIé…ç½®
        
        Args:
            api_type: APIç±»å‹
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
            model_name: æ¨¡å‹åç§°
        """
        self.api_type = api_type
        self.api_key = api_key
        self.api_base = api_base
        self.model_name = model_name
        
        # æ¸…é™¤é…ç½®ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°åŠ è½½
        self._config_cache = None
        self._config_loaded = False
    
    def get_response_with_intent(self, message: str) -> str:
        """
        è·å–æ¨¡å‹å“åº”ï¼Œæ”¯æŒæ„å›¾è¯†åˆ«å’Œæ‰§è¡ŒåŠŸèƒ½
        
        æµç¨‹ï¼šç”¨æˆ·è¾“å…¥ â†’ æ„å›¾è¯†åˆ« â†’ åŠŸèƒ½æ‰§è¡Œ â†’ åŸå§‹è¾“å…¥+æ‰§è¡Œç»“æœ â†’ LLMå¯¹è¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            æ¨¡å‹å“åº”æ–‡æœ¬
        """
        try:
            print(f"ğŸ“ ç”¨æˆ·è¾“å…¥: {message}")
            
            # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨æ–°çš„æ„å›¾å¼•æ“è¿›è¡Œæ„å›¾è¯†åˆ«å’Œæ‰§è¡Œ
            import sys
            import os
            
            # æ·»åŠ brain_agentåˆ°Pythonè·¯å¾„
            brain_agent_path = os.path.join(os.path.dirname(__file__), '..', 'brain_agent')
            if brain_agent_path not in sys.path:
                sys.path.insert(0, brain_agent_path)
            
            # å¯¼å…¥æ„å›¾å¼•æ“
            from intent_engine import IntentEngine
            
            # åˆ›å»ºæ„å›¾å¼•æ“å®ä¾‹
            # ä¼˜å…ˆä½¿ç”¨å½“å‰LLMå®¢æˆ·ç«¯çš„APIå¯†é’¥ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»ç¯å¢ƒå˜é‡è·å–
            api_key = self.api_key or os.getenv("DOUBAO_API_KEY")
            intent_engine = IntentEngine(api_key=api_key)
            
            # å¤„ç†æ¶ˆæ¯ï¼ˆæ„å›¾è¯†åˆ« + æ‰§è¡Œï¼‰
            process_result = intent_engine.process_message(message)
            
            intent_type = process_result.get('intent_data', {}).get('intent_type', 'unknown')
            confidence = process_result.get('intent_data', {}).get('confidence', 0.0)
            success = process_result.get('success', False)
            execution_result = process_result.get('response', '')
            
            print(f"ğŸ§  æ„å›¾è¯†åˆ«: {intent_type} (ç½®ä¿¡åº¦: {confidence:.2f})")
            print(f"âš¡ æ‰§è¡Œç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
            
            # ç¬¬äºŒæ­¥ï¼šæ„å»ºå¢å¼ºçš„è¾“å…¥
            enhanced_message = message
            
            # å¦‚æœæœ‰æ‰§è¡Œç»“æœï¼Œå°†å…¶æ·»åŠ åˆ°åŸå§‹è¾“å…¥ä¸­
            if success and execution_result:
                enhanced_message = f"{message}\n\n[ç³»ç»Ÿæ‰§è¡Œç»“æœ]: {execution_result}"
                print(f"ğŸ”— å¢å¼ºè¾“å…¥: {enhanced_message[:100]}...")
            elif not success:
                # æ‰§è¡Œå¤±è´¥ï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯
                error_msg = process_result.get('error', 'æ‰§è¡Œå¤±è´¥')
                enhanced_message = f"{message}\n\n[ç³»ç»Ÿæ‰§è¡Œå¤±è´¥]: {error_msg}"
                print(f"âš ï¸ æ‰§è¡Œå¤±è´¥: {error_msg}")
            
            # ç¬¬ä¸‰æ­¥ï¼šä½¿ç”¨å¢å¼ºçš„è¾“å…¥ç”ŸæˆLLMå›å¤
            final_response = self.get_response(enhanced_message)
            
            print(f"ğŸ’¬ ç”Ÿæˆå›å¤: {final_response[:100]}...")
            return final_response
                
        except Exception as e:
            print(f"âŒ æ„å›¾è¯†åˆ«å“åº”å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self.get_response(message)
    
    def _generate_comprehensive_response(self, user_message: str, intent_type: str, search_reference: str = None, search_content: List[Dict[str, str]] = None) -> str:
        """
        ç”Ÿæˆç»¼åˆå›å¤
        
        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            intent_type: æ„å›¾ç±»å‹
            search_reference: æœç´¢å‚è€ƒèµ„æ–™
            search_content: çˆ¬å–çš„æœç´¢ç»“æœå†…å®¹
            
        Returns:
            ç»¼åˆå›å¤æ–‡æœ¬
        """
        try:
            # æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
            enhanced_system_prompt = self._build_enhanced_system_prompt(intent_type, search_reference, search_content)
            
            # ä¸´æ—¶è®¾ç½®å¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
            original_prompt = self.system_prompt
            self.system_prompt = enhanced_system_prompt
            
            # ç”Ÿæˆå›å¤
            response = self.get_response(user_message)
            
            # æ¢å¤åŸå§‹ç³»ç»Ÿæç¤ºè¯
            self.system_prompt = original_prompt
            
            return response
            
        except Exception as e:
            print(f"âŒ ç»¼åˆå›å¤ç”Ÿæˆå¤±è´¥: {e}")
            return self.get_response(user_message)
    
    def _build_enhanced_system_prompt(self, intent_type: str, search_reference: str = None, search_content: List[Dict[str, str]] = None) -> str:
        """
        æ„å»ºå¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
        
        Args:
            intent_type: æ„å›¾ç±»å‹
            search_reference: æœç´¢å‚è€ƒèµ„æ–™
            search_content: çˆ¬å–çš„æœç´¢ç»“æœå†…å®¹
            
        Returns:
            å¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯
        """
        base_prompt = self.system_prompt
        
        # æ ¹æ®æ„å›¾ç±»å‹æ·»åŠ ç‰¹å®šæŒ‡å¯¼
        intent_guidance = ""
        if intent_type == 'search':
            intent_guidance = """
æœç´¢æ„å›¾æŒ‡å¯¼ï¼š
- ç”¨æˆ·éœ€è¦æŸ¥æ‰¾ä¿¡æ¯æˆ–è·å–æœ€æ–°èµ„æ–™
- è¯·åŸºäºæœç´¢ç»“æœæä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ä¿¡æ¯
- å¦‚æœæœç´¢ç»“æœä¸å¤Ÿå‡†ç¡®ï¼Œè¯·è¯´æ˜å¹¶æä¾›å»ºè®®
- ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„è¯­æ°”
- å¼•ç”¨å…·ä½“çš„æœç´¢ç»“æœæ¥æº
"""
        elif intent_type == 'chat':
            intent_guidance = """
èŠå¤©æ„å›¾æŒ‡å¯¼ï¼š
- ç”¨æˆ·å¸Œæœ›è¿›è¡Œè½»æ¾æ„‰å¿«çš„å¯¹è¯
- ä¿æŒæ¸©æš–ã€å‹å–„çš„è¯­æ°”
- é€‚å½“ä½¿ç”¨emojiè¡¨æƒ…
- å…³æ³¨ç”¨æˆ·çš„æƒ…æ„Ÿéœ€æ±‚
"""
        elif intent_type == 'config':
            intent_guidance = """
é…ç½®æ„å›¾æŒ‡å¯¼ï¼š
- ç”¨æˆ·éœ€è¦é…ç½®ç³»ç»Ÿå‚æ•°
- æä¾›æ¸…æ™°çš„é…ç½®æŒ‡å¯¼
- ç¡®ä¿é…ç½®ä¿¡æ¯çš„å®‰å…¨æ€§
- éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§
"""
        elif intent_type == 'help':
            intent_guidance = """
å¸®åŠ©æ„å›¾æŒ‡å¯¼ï¼š
- ç”¨æˆ·éœ€è¦äº†è§£åŠŸèƒ½æˆ–ä½¿ç”¨æ–¹æ³•
- æä¾›è¯¦ç»†ã€æ˜“æ‡‚çš„è¯´æ˜
- ä½¿ç”¨å…·ä½“çš„ä¾‹å­
- å¼•å¯¼ç”¨æˆ·æ­£ç¡®ä½¿ç”¨åŠŸèƒ½
"""
        elif intent_type == 'meditation':
            intent_guidance = """
å†¥æƒ³æ„å›¾æŒ‡å¯¼ï¼š
- ç”¨æˆ·éœ€è¦è¿›è¡Œè®°å¿†ç¼–ç æˆ–å†¥æƒ³
- æä¾›ä¸“ä¸šçš„å†¥æƒ³æŒ‡å¯¼
- ç¡®ä¿å†¥æƒ³è¿‡ç¨‹çš„å®‰å…¨æ€§
- å…³æ³¨ç”¨æˆ·çš„èº«å¿ƒçŠ¶æ€
"""
        
        # æ·»åŠ æœç´¢å‚è€ƒèµ„æ–™
        search_context = ""
        if search_reference:
            search_context = f"""
æœç´¢å‚è€ƒèµ„æ–™ï¼š
{search_reference}
"""
        
        # æ·»åŠ çˆ¬å–çš„æœç´¢ç»“æœå†…å®¹
        if search_content:
            from .search_module import search_module
            search_summary = search_module.get_search_summary(search_content)
            search_context += f"""

è¯¦ç»†æœç´¢ç»“æœï¼š
{search_summary}

è¯·åŸºäºä»¥ä¸Šæœç´¢ç»“æœå›ç­”ç”¨æˆ·é—®é¢˜ï¼Œç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§ã€‚å¯ä»¥å¼•ç”¨å…·ä½“çš„æœç´¢ç»“æœæ¥æºã€‚
"""
        elif search_reference:
            search_context += """

è¯·åŸºäºä»¥ä¸Šæœç´¢ç»“æœå›ç­”ç”¨æˆ·é—®é¢˜ï¼Œç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§ã€‚
"""
        
        # ç»„åˆæœ€ç»ˆçš„æç¤ºè¯
        enhanced_prompt = f"{base_prompt}\n\n{intent_guidance}\n{search_context}"
        
        return enhanced_prompt.strip()
    
    def get_response_with_search(self, message: str) -> str:
        """
        è·å–æ¨¡å‹å“åº”ï¼Œæ”¯æŒæœç´¢åŠŸèƒ½ï¼ˆå‘åå…¼å®¹ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            æ¨¡å‹å“åº”æ–‡æœ¬
        """
        return self.get_response_with_intent(message)
    
    def _should_search(self, message: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢"""
        search_keywords = [
            'æœç´¢', 'æŸ¥æ‰¾', 'æ‰¾', 'å¸®æˆ‘æ‰¾', 'å¸®æˆ‘æœç´¢', 'å¸®æˆ‘æŸ¥æ‰¾',
            'search', 'find', 'look for', 'help me find'
        ]
        
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in search_keywords)
    
    def _perform_search_with_query(self, query: str) -> Dict[str, Any]:
        """ä½¿ç”¨æŒ‡å®šæŸ¥è¯¢æ‰§è¡Œæœç´¢"""
        try:
            from .search_module import search_module
            
            if not query:
                return {
                    'success': False,
                    'error': 'æœç´¢æŸ¥è¯¢ä¸ºç©º',
                    'message': 'âŒ æœç´¢æŸ¥è¯¢ä¸èƒ½ä¸ºç©º'
                }
            
            # æ‰§è¡Œæ™ºèƒ½æœç´¢
            result = search_module.smart_search(query)
            return result
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'message': f'âŒ æœç´¢æ‰§è¡Œå¤±è´¥: {str(e)}'
            }
    
    def _perform_search(self, message: str) -> Dict[str, Any]:
        """æ‰§è¡Œæœç´¢ï¼ˆå‘åå…¼å®¹ï¼‰"""
        try:
            from .search_module import search_module
            
            # æå–æœç´¢æŸ¥è¯¢
            query = self._extract_search_query(message)
            if not query:
                return {
                    'success': False,
                    'error': 'æ— æ³•æå–æœç´¢æŸ¥è¯¢',
                    'message': 'âŒ æ— æ³•ç†è§£æœç´¢è¯·æ±‚'
                }
            
            # æ‰§è¡Œæ™ºèƒ½æœç´¢
            result = search_module.smart_search(query)
            return result
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'message': f'âŒ æœç´¢æ‰§è¡Œå¤±è´¥: {str(e)}'
            }
    
    def _extract_search_query(self, message: str) -> str:
        """ä»æ¶ˆæ¯ä¸­æå–æœç´¢æŸ¥è¯¢"""
        # ç§»é™¤æœç´¢å…³é”®è¯
        search_keywords = [
            'æœç´¢', 'æŸ¥æ‰¾', 'æ‰¾', 'å¸®æˆ‘æ‰¾', 'å¸®æˆ‘æœç´¢', 'å¸®æˆ‘æŸ¥æ‰¾',
            'search', 'find', 'look for', 'help me find'
        ]
        
        query = message
        for keyword in search_keywords:
            if keyword in query.lower():
                # ç§»é™¤å…³é”®è¯åŠå…¶å‰åçš„ç©ºæ ¼
                query = query.replace(keyword, '').replace('å¸®æˆ‘', '').strip()
                break
        
        return query 